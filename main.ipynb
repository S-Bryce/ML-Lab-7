{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Group\n",
    "Lab Assignment Seven: RNNs\n",
    "Wali Chaudhary, Bryce Shurts, & Alex Wright"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "The dataset is sourced from data.world on Kaggle, and is called \"Emotion Detection from Text\". It was distributed by data.world under a public license according to the source. The dataset is a collection of tweets annotated with emotions attached to each sample.\n",
    "\n",
    "There exist 3 columns, \"tweet_id\", \"sentiment\", and \"content\". Tweet_id represents the identification number of the tweet for querying with the Twitter API, sentiment is the classification of emotion associated with the content, and content is the raw text from the tweet.\n",
    "\n",
    "The dataset contains 13 different emotions, with 40000 records. The dataset is imbalanced, as there are a different number of records per emotion, so this must be addressed in preprocessing the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "\n",
    "#### Splitting the data\n",
    "We will be using Stratified K-Fold Cross Validation to split our data into training and testing sets. We chose this method based on the structure of our dataset.\n",
    "\n",
    "The dataset contains imbalanced classes, so we want to ensure that the distribution of the training & testing sets are representative of the overall distribution of classes in the dataset and is beneficial to reducing bias. Features like the sentiment feature are imbalanced with each of the 13 values associated with it having a different distribution across the dataset. Stratified K-Fold Cross Validation ensures this proportionality of distribution, unlike a normal train test split which randomly splits the data into two sets based on a predefined ratio. This can result in a skewed representation of classes in the training & testing datasets not representative of the distribution of the entire dataset.\n",
    "\n",
    "Stratified K-Fold Cross Validation also gives us the advantage of being able to compare different models as each model is trained differently per fold. This will help us in hyper parameter tuning.\n",
    "\n",
    "\n",
    "#### Tokenization methods, Vocabulary, and content length\n",
    "\n",
    "We use the Keras Tokenizer class to tokenize the text data in our dataset. We convert each tweet's text into a sequence of integers, where each integer represents a unique word in the vocabulary. The Tokenizer also takes care of lowercasing, removing punctuation, and handling out-of-vocabulary words.\n",
    "\n",
    "We defined our vocabulary to use all the unique words in \"content\", this was because we didn't want to lose any data as we thought this would also generalize our model better overall. Although this will increase the complexity of our model, and one could also argue that mispellings and grammatical errors can lead to an incorrect classification; we believe that grammatical errors and slang are common ways of emotional expression online. For example, if a user tweets GAAAAAHHHH, that probably means they're very upset versus someone who tweets GAH which may indicate surprise.\n",
    "\n",
    "We decided to keep the length of each sequence to the longest individual sequence by using padding, as this'll help us capture the maximum amount of input for sentiment analysis.\n",
    "\n",
    "\n",
    "#### Evaluation Metrics\n",
    "\n",
    "For evaluation, we decided to rely on the F1 score, precision, recall, and accuracy. This is because we are performing a classification task on sequences to predict sentiment. Precision is important because it helps us guage the our models True positive predictiveness, and recall helps us identify the number of positive instances correctly identified out of the total amount of positive cases. In our specific case, recall is important because it'll tell us the ratio of how much our classifier was able to identify correct sentiment, like happiness, out the all of the happiness records. Precision will tell us if our evaluation of sentiment was correct.\n",
    "\n",
    "The F1 score balances both of these metrics together, and provides a balanced measure of our models performance. In sentiment analysis, false positives and false negatives are not good because both types of errors can have significant consequences, especially in a system which relies on the classification to provide recommendations or critical information. A high F1-score indicates that our model is making accurate positive predictions while minimizing false positives and false negatives. It is also useful in our case as well since our dataset is imbalanced, because it reduces bias to the majority class by giving a balanced result of the recall and precision to account for both false positives and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T03:20:20.332058Z",
     "start_time": "2023-05-09T03:20:20.327349Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Handle all imports for notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from skimage.transform import resize\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, classification_report\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T03:20:20.650688Z",
     "start_time": "2023-05-09T03:20:20.574487Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweet_emotions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T03:20:20.721262Z",
     "start_time": "2023-05-09T03:20:20.657716Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>fuckin'm transtelecom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boredom</th>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>i'm so tired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empty</th>\n",
       "      <td>827</td>\n",
       "      <td>827</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enthusiasm</th>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>1776</td>\n",
       "      <td>1776</td>\n",
       "      <td>Wondering why I'm awake at 7am,writing a new s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happiness</th>\n",
       "      <td>5209</td>\n",
       "      <td>5194</td>\n",
       "      <td>FREE UNLIMITED RINGTONES!!! - http://tinyurl.c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>1323</td>\n",
       "      <td>1323</td>\n",
       "      <td>It is so annoying when she starts typing on he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>3842</td>\n",
       "      <td>3801</td>\n",
       "      <td>I just received a mothers day card from my lov...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>8638</td>\n",
       "      <td>8617</td>\n",
       "      <td>FREE UNLIMITED RINGTONES!!! - http://tinyurl.c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>1526</td>\n",
       "      <td>1524</td>\n",
       "      <td>http://snipurl.com/hq0n1 Just printed my mom a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>5165</td>\n",
       "      <td>5160</td>\n",
       "      <td>at home sick</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>2187</td>\n",
       "      <td>2187</td>\n",
       "      <td>Got the news</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worry</th>\n",
       "      <td>8459</td>\n",
       "      <td>8452</td>\n",
       "      <td>i have a headache</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           content                                                            \\\n",
       "             count unique                                                top   \n",
       "sentiment                                                                      \n",
       "anger          110    110                              fuckin'm transtelecom   \n",
       "boredom        179    179                                       i'm so tired   \n",
       "empty          827    827  @tiffanylue i know  i was listenin to bad habi...   \n",
       "enthusiasm     759    759               wants to hang out with friends SOON!   \n",
       "fun           1776   1776  Wondering why I'm awake at 7am,writing a new s...   \n",
       "happiness     5209   5194  FREE UNLIMITED RINGTONES!!! - http://tinyurl.c...   \n",
       "hate          1323   1323  It is so annoying when she starts typing on he...   \n",
       "love          3842   3801  I just received a mothers day card from my lov...   \n",
       "neutral       8638   8617  FREE UNLIMITED RINGTONES!!! - http://tinyurl.c...   \n",
       "relief        1526   1524  http://snipurl.com/hq0n1 Just printed my mom a...   \n",
       "sadness       5165   5160                                       at home sick   \n",
       "surprise      2187   2187                                       Got the news   \n",
       "worry         8459   8452                                  i have a headache   \n",
       "\n",
       "                 \n",
       "           freq  \n",
       "sentiment        \n",
       "anger         1  \n",
       "boredom       1  \n",
       "empty         1  \n",
       "enthusiasm    1  \n",
       "fun           1  \n",
       "happiness     4  \n",
       "hate          1  \n",
       "love         13  \n",
       "neutral       4  \n",
       "relief        2  \n",
       "sadness       2  \n",
       "surprise      1  \n",
       "worry         3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "df.drop(\"tweet_id\", inplace=True, axis=1)\n",
    "\n",
    "df.groupby(df[\"sentiment\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that the sentiment feature is very imbalanced, with each of its 13 values having a different distribution across the dataset. The highest value, happiness with 5209 in count is significantly higher than the lowest count, anger, which has only 110 records.\n",
    "\n",
    "Dropped the \"twitter_id\" column as that was not relevant to the task at hand for classifying sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T03:20:20.741082Z",
     "start_time": "2023-05-09T03:20:20.734223Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the Stratified Shuffle Split object\n",
    "n_splits = 3\n",
    "test_size = 0.2\n",
    "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "X, y = df.drop(\"sentiment\", inplace=False, axis=1), df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T03:20:22.876505Z",
     "start_time": "2023-05-09T03:20:20.746945Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#tokenize the text, use entire vocabulary\n",
    "tokenizer = Tokenizer()\n",
    "y_np = y.to_numpy().reshape(-1, 1)\n",
    "\n",
    "# save as sequences with integers replacing words\n",
    "tokenizer.fit_on_texts(X[\"content\"])\n",
    "sequences = tokenizer.texts_to_sequences(X[\"content\"])\n",
    "final_seqs = pad_sequences(sequences,maxlen=300)\n",
    "num_vocab = len(tokenizer.word_index)+1\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "target = encoder.fit_transform(y_np).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T03:20:22.888748Z",
     "start_time": "2023-05-09T03:20:22.886196Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load in the word embeddings\n",
    "word_vectors = {}\n",
    "for line in open(\"glove.840B.300d.txt\"):\n",
    "    value = line.split(' ')\n",
    "    word_vectors[value[0]] = np.array(value[1:],dtype = 'float32')\n",
    "\n",
    "# Apply embeddings to dataset\n",
    "embedding_matrix = np.zeros((num_vocab, 300))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding = word_vectors.get(word)\n",
    "    if embedding is not None:\n",
    "        embedding_matrix[index] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 15s 68ms/step - loss: 0.2983 - accuracy: 0.1922 - val_loss: 0.2365 - val_accuracy: 0.2291\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2301 - accuracy: 0.2838 - val_loss: 0.2298 - val_accuracy: 0.2788\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2223 - accuracy: 0.3272 - val_loss: 0.2240 - val_accuracy: 0.3206\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2173 - accuracy: 0.3444 - val_loss: 0.2209 - val_accuracy: 0.3150\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2141 - accuracy: 0.3521 - val_loss: 0.2173 - val_accuracy: 0.3408\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2112 - accuracy: 0.3670 - val_loss: 0.2148 - val_accuracy: 0.3512\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2090 - accuracy: 0.3738 - val_loss: 0.2139 - val_accuracy: 0.3477\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2070 - accuracy: 0.3819 - val_loss: 0.2139 - val_accuracy: 0.3492\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2053 - accuracy: 0.3900 - val_loss: 0.2116 - val_accuracy: 0.3592\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2038 - accuracy: 0.3958 - val_loss: 0.2115 - val_accuracy: 0.3614\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2026 - accuracy: 0.4004 - val_loss: 0.2114 - val_accuracy: 0.3642\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2014 - accuracy: 0.4011 - val_loss: 0.2119 - val_accuracy: 0.3598\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2000 - accuracy: 0.4073 - val_loss: 0.2120 - val_accuracy: 0.3672\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1993 - accuracy: 0.4121 - val_loss: 0.2125 - val_accuracy: 0.3602\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1978 - accuracy: 0.4174 - val_loss: 0.2117 - val_accuracy: 0.3667\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1966 - accuracy: 0.4225 - val_loss: 0.2128 - val_accuracy: 0.3631\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1950 - accuracy: 0.4271 - val_loss: 0.2131 - val_accuracy: 0.3605\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1938 - accuracy: 0.4305 - val_loss: 0.2129 - val_accuracy: 0.3655\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1923 - accuracy: 0.4375 - val_loss: 0.2132 - val_accuracy: 0.3642\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1908 - accuracy: 0.4429 - val_loss: 0.2154 - val_accuracy: 0.3608\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1890 - accuracy: 0.4491 - val_loss: 0.2157 - val_accuracy: 0.3613\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1873 - accuracy: 0.4563 - val_loss: 0.2161 - val_accuracy: 0.3620\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1855 - accuracy: 0.4631 - val_loss: 0.2182 - val_accuracy: 0.3478\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1834 - accuracy: 0.4703 - val_loss: 0.2190 - val_accuracy: 0.3448\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1816 - accuracy: 0.4792 - val_loss: 0.2208 - val_accuracy: 0.3464\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1795 - accuracy: 0.4877 - val_loss: 0.2223 - val_accuracy: 0.3503\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1769 - accuracy: 0.4993 - val_loss: 0.2231 - val_accuracy: 0.3433\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1749 - accuracy: 0.5072 - val_loss: 0.2245 - val_accuracy: 0.3445\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1724 - accuracy: 0.5173 - val_loss: 0.2266 - val_accuracy: 0.3417\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1702 - accuracy: 0.5261 - val_loss: 0.2274 - val_accuracy: 0.3413\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1678 - accuracy: 0.5360 - val_loss: 0.2314 - val_accuracy: 0.3416\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1647 - accuracy: 0.5501 - val_loss: 0.2327 - val_accuracy: 0.3395\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1620 - accuracy: 0.5586 - val_loss: 0.2387 - val_accuracy: 0.3320\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1594 - accuracy: 0.5688 - val_loss: 0.2387 - val_accuracy: 0.3328\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1573 - accuracy: 0.5761 - val_loss: 0.2411 - val_accuracy: 0.3269\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1542 - accuracy: 0.5889 - val_loss: 0.2433 - val_accuracy: 0.3292\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1517 - accuracy: 0.5980 - val_loss: 0.2471 - val_accuracy: 0.3272\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1494 - accuracy: 0.6055 - val_loss: 0.2485 - val_accuracy: 0.3255\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1469 - accuracy: 0.6164 - val_loss: 0.2523 - val_accuracy: 0.3267\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1438 - accuracy: 0.6279 - val_loss: 0.2603 - val_accuracy: 0.3239\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1414 - accuracy: 0.6341 - val_loss: 0.2620 - val_accuracy: 0.3280\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1383 - accuracy: 0.6455 - val_loss: 0.2688 - val_accuracy: 0.3212\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1357 - accuracy: 0.6552 - val_loss: 0.2699 - val_accuracy: 0.3216\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1334 - accuracy: 0.6638 - val_loss: 0.2726 - val_accuracy: 0.3197\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1298 - accuracy: 0.6753 - val_loss: 0.2791 - val_accuracy: 0.3128\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1281 - accuracy: 0.6811 - val_loss: 0.2842 - val_accuracy: 0.3114\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1252 - accuracy: 0.6905 - val_loss: 0.2902 - val_accuracy: 0.3047\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1229 - accuracy: 0.6966 - val_loss: 0.2942 - val_accuracy: 0.3055\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1200 - accuracy: 0.7074 - val_loss: 0.2983 - val_accuracy: 0.3033\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1170 - accuracy: 0.7164 - val_loss: 0.3039 - val_accuracy: 0.3005\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1146 - accuracy: 0.7243 - val_loss: 0.3111 - val_accuracy: 0.2998\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1124 - accuracy: 0.7303 - val_loss: 0.3158 - val_accuracy: 0.3023\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1093 - accuracy: 0.7409 - val_loss: 0.3240 - val_accuracy: 0.3034\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1080 - accuracy: 0.7432 - val_loss: 0.3245 - val_accuracy: 0.2988\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1046 - accuracy: 0.7554 - val_loss: 0.3335 - val_accuracy: 0.2933\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1024 - accuracy: 0.7620 - val_loss: 0.3387 - val_accuracy: 0.2980\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1002 - accuracy: 0.7655 - val_loss: 0.3449 - val_accuracy: 0.2930\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0971 - accuracy: 0.7760 - val_loss: 0.3551 - val_accuracy: 0.2944\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0958 - accuracy: 0.7785 - val_loss: 0.3594 - val_accuracy: 0.2916\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0938 - accuracy: 0.7862 - val_loss: 0.3627 - val_accuracy: 0.2903\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0904 - accuracy: 0.7948 - val_loss: 0.3750 - val_accuracy: 0.2928\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0888 - accuracy: 0.8010 - val_loss: 0.3804 - val_accuracy: 0.2897\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0869 - accuracy: 0.8070 - val_loss: 0.3836 - val_accuracy: 0.2912\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0843 - accuracy: 0.8124 - val_loss: 0.3947 - val_accuracy: 0.2894\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0834 - accuracy: 0.8130 - val_loss: 0.4011 - val_accuracy: 0.2889\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0825 - accuracy: 0.8144 - val_loss: 0.4031 - val_accuracy: 0.2837\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0805 - accuracy: 0.8201 - val_loss: 0.4145 - val_accuracy: 0.2900\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0777 - accuracy: 0.8279 - val_loss: 0.4200 - val_accuracy: 0.2850\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0768 - accuracy: 0.8296 - val_loss: 0.4296 - val_accuracy: 0.2837\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0734 - accuracy: 0.8402 - val_loss: 0.4356 - val_accuracy: 0.2789\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0733 - accuracy: 0.8389 - val_loss: 0.4536 - val_accuracy: 0.2794\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0719 - accuracy: 0.8435 - val_loss: 0.4450 - val_accuracy: 0.2814\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0706 - accuracy: 0.8436 - val_loss: 0.4572 - val_accuracy: 0.2812\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0694 - accuracy: 0.8499 - val_loss: 0.4694 - val_accuracy: 0.2837\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0683 - accuracy: 0.8545 - val_loss: 0.4732 - val_accuracy: 0.2753\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0664 - accuracy: 0.8579 - val_loss: 0.4840 - val_accuracy: 0.2764\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0647 - accuracy: 0.8623 - val_loss: 0.4876 - val_accuracy: 0.2825\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0623 - accuracy: 0.8681 - val_loss: 0.4961 - val_accuracy: 0.2772\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0612 - accuracy: 0.8730 - val_loss: 0.5070 - val_accuracy: 0.2769\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0603 - accuracy: 0.8728 - val_loss: 0.5083 - val_accuracy: 0.2775\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0644 - accuracy: 0.8616 - val_loss: 0.5085 - val_accuracy: 0.2803\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0601 - accuracy: 0.8745 - val_loss: 0.5268 - val_accuracy: 0.2770\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0559 - accuracy: 0.8843 - val_loss: 0.5350 - val_accuracy: 0.2792\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0574 - accuracy: 0.8797 - val_loss: 0.5360 - val_accuracy: 0.2700\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0560 - accuracy: 0.8841 - val_loss: 0.5474 - val_accuracy: 0.2803\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0529 - accuracy: 0.8921 - val_loss: 0.5612 - val_accuracy: 0.2759\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0519 - accuracy: 0.8950 - val_loss: 0.5630 - val_accuracy: 0.2744\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0535 - accuracy: 0.8895 - val_loss: 0.5717 - val_accuracy: 0.2689\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0539 - accuracy: 0.8895 - val_loss: 0.5759 - val_accuracy: 0.2736\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0579 - accuracy: 0.8778 - val_loss: 0.5675 - val_accuracy: 0.2709\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0504 - accuracy: 0.8991 - val_loss: 0.5852 - val_accuracy: 0.2697\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0469 - accuracy: 0.9067 - val_loss: 0.5867 - val_accuracy: 0.2702\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0458 - accuracy: 0.9096 - val_loss: 0.6067 - val_accuracy: 0.2733\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0496 - accuracy: 0.9008 - val_loss: 0.6096 - val_accuracy: 0.2711\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0465 - accuracy: 0.9076 - val_loss: 0.6165 - val_accuracy: 0.2717\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0470 - accuracy: 0.9054 - val_loss: 0.6261 - val_accuracy: 0.2702\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0450 - accuracy: 0.9119 - val_loss: 0.6298 - val_accuracy: 0.2695\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0440 - accuracy: 0.9143 - val_loss: 0.6277 - val_accuracy: 0.2742\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0447 - accuracy: 0.9114 - val_loss: 0.6378 - val_accuracy: 0.2714\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0404 - accuracy: 0.9230 - val_loss: 0.6584 - val_accuracy: 0.2703\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 0.2070 - accuracy: 0.6045 - val_loss: 0.1897 - val_accuracy: 0.5822\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1629 - accuracy: 0.6400 - val_loss: 0.1844 - val_accuracy: 0.6002\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1501 - accuracy: 0.6680 - val_loss: 0.1824 - val_accuracy: 0.6027\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1419 - accuracy: 0.6806 - val_loss: 0.1850 - val_accuracy: 0.5995\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1353 - accuracy: 0.6955 - val_loss: 0.1864 - val_accuracy: 0.6005\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1295 - accuracy: 0.7055 - val_loss: 0.1913 - val_accuracy: 0.5984\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1241 - accuracy: 0.7126 - val_loss: 0.1932 - val_accuracy: 0.5898\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1192 - accuracy: 0.7226 - val_loss: 0.1943 - val_accuracy: 0.5841\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1147 - accuracy: 0.7337 - val_loss: 0.1995 - val_accuracy: 0.5769\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1105 - accuracy: 0.7432 - val_loss: 0.2043 - val_accuracy: 0.5741\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1072 - accuracy: 0.7486 - val_loss: 0.2072 - val_accuracy: 0.5661\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1051 - accuracy: 0.7539 - val_loss: 0.2116 - val_accuracy: 0.5584\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1036 - accuracy: 0.7566 - val_loss: 0.2165 - val_accuracy: 0.5547\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0989 - accuracy: 0.7684 - val_loss: 0.2129 - val_accuracy: 0.5561\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0954 - accuracy: 0.7785 - val_loss: 0.2231 - val_accuracy: 0.5492\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0936 - accuracy: 0.7829 - val_loss: 0.2241 - val_accuracy: 0.5461\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0919 - accuracy: 0.7853 - val_loss: 0.2270 - val_accuracy: 0.5369\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0897 - accuracy: 0.7922 - val_loss: 0.2342 - val_accuracy: 0.5381\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0877 - accuracy: 0.7968 - val_loss: 0.2334 - val_accuracy: 0.5347\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0857 - accuracy: 0.8025 - val_loss: 0.2406 - val_accuracy: 0.5402\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0888 - accuracy: 0.7935 - val_loss: 0.2449 - val_accuracy: 0.5284\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0823 - accuracy: 0.8106 - val_loss: 0.2539 - val_accuracy: 0.5288\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0802 - accuracy: 0.8146 - val_loss: 0.2537 - val_accuracy: 0.5136\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0788 - accuracy: 0.8198 - val_loss: 0.2584 - val_accuracy: 0.5120\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0764 - accuracy: 0.8256 - val_loss: 0.2589 - val_accuracy: 0.5178\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0818 - accuracy: 0.8105 - val_loss: 0.2638 - val_accuracy: 0.5069\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0746 - accuracy: 0.8299 - val_loss: 0.2756 - val_accuracy: 0.5133\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0713 - accuracy: 0.8379 - val_loss: 0.2696 - val_accuracy: 0.5055\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0695 - accuracy: 0.8423 - val_loss: 0.2750 - val_accuracy: 0.5052\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0673 - accuracy: 0.8480 - val_loss: 0.2882 - val_accuracy: 0.5006\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0664 - accuracy: 0.8507 - val_loss: 0.2927 - val_accuracy: 0.4988\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0676 - accuracy: 0.8468 - val_loss: 0.2933 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0674 - accuracy: 0.8474 - val_loss: 0.3029 - val_accuracy: 0.4922\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0653 - accuracy: 0.8530 - val_loss: 0.3018 - val_accuracy: 0.4877\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0642 - accuracy: 0.8553 - val_loss: 0.3126 - val_accuracy: 0.4923\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0615 - accuracy: 0.8615 - val_loss: 0.3076 - val_accuracy: 0.4870\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0595 - accuracy: 0.8667 - val_loss: 0.3288 - val_accuracy: 0.4886\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0578 - accuracy: 0.8697 - val_loss: 0.3240 - val_accuracy: 0.4784\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0572 - accuracy: 0.8722 - val_loss: 0.3297 - val_accuracy: 0.4709\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0599 - accuracy: 0.8649 - val_loss: 0.3271 - val_accuracy: 0.4816\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0586 - accuracy: 0.8684 - val_loss: 0.3449 - val_accuracy: 0.4780\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0559 - accuracy: 0.8747 - val_loss: 0.3321 - val_accuracy: 0.4712\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0539 - accuracy: 0.8799 - val_loss: 0.3537 - val_accuracy: 0.4711\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0533 - accuracy: 0.8806 - val_loss: 0.3491 - val_accuracy: 0.4711\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0519 - accuracy: 0.8848 - val_loss: 0.3617 - val_accuracy: 0.4644\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0516 - accuracy: 0.8846 - val_loss: 0.3642 - val_accuracy: 0.4659\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0490 - accuracy: 0.8921 - val_loss: 0.3674 - val_accuracy: 0.4684\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0478 - accuracy: 0.8954 - val_loss: 0.3808 - val_accuracy: 0.4692\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 0.0487 - accuracy: 0.8918 - val_loss: 0.3713 - val_accuracy: 0.4623\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0491 - accuracy: 0.8913 - val_loss: 0.3837 - val_accuracy: 0.4639\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0572 - accuracy: 0.8719 - val_loss: 0.3711 - val_accuracy: 0.4517\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0510 - accuracy: 0.8854 - val_loss: 0.3855 - val_accuracy: 0.4580\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0457 - accuracy: 0.8995 - val_loss: 0.3987 - val_accuracy: 0.4611\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0463 - accuracy: 0.8995 - val_loss: 0.4056 - val_accuracy: 0.4545\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0472 - accuracy: 0.8959 - val_loss: 0.3985 - val_accuracy: 0.4466\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0471 - accuracy: 0.8952 - val_loss: 0.4063 - val_accuracy: 0.4536\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0432 - accuracy: 0.9055 - val_loss: 0.4149 - val_accuracy: 0.4570\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0431 - accuracy: 0.9046 - val_loss: 0.4099 - val_accuracy: 0.4489\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0417 - accuracy: 0.9089 - val_loss: 0.4292 - val_accuracy: 0.4464\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0400 - accuracy: 0.9128 - val_loss: 0.4388 - val_accuracy: 0.4487\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0379 - accuracy: 0.9185 - val_loss: 0.4385 - val_accuracy: 0.4527\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0364 - accuracy: 0.9224 - val_loss: 0.4456 - val_accuracy: 0.4497\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0366 - accuracy: 0.9203 - val_loss: 0.4421 - val_accuracy: 0.4462\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0377 - accuracy: 0.9190 - val_loss: 0.4567 - val_accuracy: 0.4511\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0446 - accuracy: 0.9018 - val_loss: 0.4479 - val_accuracy: 0.4398\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0447 - accuracy: 0.9023 - val_loss: 0.4539 - val_accuracy: 0.4467\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0425 - accuracy: 0.9082 - val_loss: 0.4473 - val_accuracy: 0.4406\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0453 - accuracy: 0.9007 - val_loss: 0.4446 - val_accuracy: 0.4348\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0398 - accuracy: 0.9138 - val_loss: 0.4536 - val_accuracy: 0.4400\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0367 - accuracy: 0.9209 - val_loss: 0.4642 - val_accuracy: 0.4423\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0357 - accuracy: 0.9226 - val_loss: 0.4781 - val_accuracy: 0.4442\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0335 - accuracy: 0.9287 - val_loss: 0.4697 - val_accuracy: 0.4444\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0324 - accuracy: 0.9307 - val_loss: 0.4869 - val_accuracy: 0.4495\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0307 - accuracy: 0.9345 - val_loss: 0.4885 - val_accuracy: 0.4333\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0322 - accuracy: 0.9308 - val_loss: 0.4889 - val_accuracy: 0.4331\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0348 - accuracy: 0.9250 - val_loss: 0.4921 - val_accuracy: 0.4370\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0384 - accuracy: 0.9167 - val_loss: 0.4809 - val_accuracy: 0.4283\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0443 - accuracy: 0.9047 - val_loss: 0.5030 - val_accuracy: 0.4386\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0382 - accuracy: 0.9173 - val_loss: 0.4891 - val_accuracy: 0.4292\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0344 - accuracy: 0.9255 - val_loss: 0.5045 - val_accuracy: 0.4289\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0305 - accuracy: 0.9355 - val_loss: 0.5060 - val_accuracy: 0.4322\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0287 - accuracy: 0.9373 - val_loss: 0.5213 - val_accuracy: 0.4281\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0270 - accuracy: 0.9414 - val_loss: 0.5313 - val_accuracy: 0.4347\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0263 - accuracy: 0.9436 - val_loss: 0.5327 - val_accuracy: 0.4281\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0255 - accuracy: 0.9463 - val_loss: 0.5426 - val_accuracy: 0.4269\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0291 - accuracy: 0.9383 - val_loss: 0.5366 - val_accuracy: 0.4259\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0553 - accuracy: 0.8821 - val_loss: 0.5133 - val_accuracy: 0.4106\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0411 - accuracy: 0.9118 - val_loss: 0.5176 - val_accuracy: 0.4166\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0323 - accuracy: 0.9317 - val_loss: 0.5335 - val_accuracy: 0.4219\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0275 - accuracy: 0.9418 - val_loss: 0.5436 - val_accuracy: 0.4256\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0254 - accuracy: 0.9469 - val_loss: 0.5447 - val_accuracy: 0.4313\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0245 - accuracy: 0.9486 - val_loss: 0.5476 - val_accuracy: 0.4267\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0236 - accuracy: 0.9513 - val_loss: 0.5576 - val_accuracy: 0.4281\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0225 - accuracy: 0.9534 - val_loss: 0.5688 - val_accuracy: 0.4252\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0225 - accuracy: 0.9536 - val_loss: 0.5693 - val_accuracy: 0.4223\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0224 - accuracy: 0.9537 - val_loss: 0.5805 - val_accuracy: 0.4225\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0248 - accuracy: 0.9484 - val_loss: 0.5819 - val_accuracy: 0.4206\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0334 - accuracy: 0.9300 - val_loss: 0.5707 - val_accuracy: 0.4184\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0346 - accuracy: 0.9268 - val_loss: 0.5853 - val_accuracy: 0.4173\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0349 - accuracy: 0.9262 - val_loss: 0.5759 - val_accuracy: 0.4231\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 0.1937 - accuracy: 0.6129 - val_loss: 0.1790 - val_accuracy: 0.5898\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1468 - accuracy: 0.6721 - val_loss: 0.1674 - val_accuracy: 0.6539\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1263 - accuracy: 0.7179 - val_loss: 0.1731 - val_accuracy: 0.6575\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1146 - accuracy: 0.7395 - val_loss: 0.1715 - val_accuracy: 0.6633\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1051 - accuracy: 0.7604 - val_loss: 0.1728 - val_accuracy: 0.6783\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0969 - accuracy: 0.7782 - val_loss: 0.1777 - val_accuracy: 0.6755\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0909 - accuracy: 0.7892 - val_loss: 0.1740 - val_accuracy: 0.6742\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0860 - accuracy: 0.7999 - val_loss: 0.1784 - val_accuracy: 0.6681\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0824 - accuracy: 0.8083 - val_loss: 0.1831 - val_accuracy: 0.6598\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0784 - accuracy: 0.8175 - val_loss: 0.1834 - val_accuracy: 0.6655\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0746 - accuracy: 0.8258 - val_loss: 0.1896 - val_accuracy: 0.6705\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0719 - accuracy: 0.8311 - val_loss: 0.1930 - val_accuracy: 0.6673\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0708 - accuracy: 0.8339 - val_loss: 0.1981 - val_accuracy: 0.6434\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0677 - accuracy: 0.8388 - val_loss: 0.2019 - val_accuracy: 0.6505\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0652 - accuracy: 0.8458 - val_loss: 0.2012 - val_accuracy: 0.6502\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0620 - accuracy: 0.8529 - val_loss: 0.2089 - val_accuracy: 0.6459\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0620 - accuracy: 0.8530 - val_loss: 0.2085 - val_accuracy: 0.6445\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0613 - accuracy: 0.8553 - val_loss: 0.2160 - val_accuracy: 0.6338\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0616 - accuracy: 0.8537 - val_loss: 0.2182 - val_accuracy: 0.6333\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0579 - accuracy: 0.8623 - val_loss: 0.2266 - val_accuracy: 0.6250\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0569 - accuracy: 0.8667 - val_loss: 0.2243 - val_accuracy: 0.6256\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0546 - accuracy: 0.8701 - val_loss: 0.2332 - val_accuracy: 0.6166\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0572 - accuracy: 0.8635 - val_loss: 0.2275 - val_accuracy: 0.6255\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0522 - accuracy: 0.8754 - val_loss: 0.2340 - val_accuracy: 0.6250\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0504 - accuracy: 0.8793 - val_loss: 0.2364 - val_accuracy: 0.6230\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0489 - accuracy: 0.8840 - val_loss: 0.2419 - val_accuracy: 0.6225\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0484 - accuracy: 0.8857 - val_loss: 0.2496 - val_accuracy: 0.6212\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0497 - accuracy: 0.8830 - val_loss: 0.2568 - val_accuracy: 0.6064\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0494 - accuracy: 0.8827 - val_loss: 0.2525 - val_accuracy: 0.6087\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0475 - accuracy: 0.8891 - val_loss: 0.2596 - val_accuracy: 0.6066\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0459 - accuracy: 0.8924 - val_loss: 0.2592 - val_accuracy: 0.6070\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0467 - accuracy: 0.8908 - val_loss: 0.2622 - val_accuracy: 0.6009\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0489 - accuracy: 0.8848 - val_loss: 0.2655 - val_accuracy: 0.5894\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0475 - accuracy: 0.8889 - val_loss: 0.2714 - val_accuracy: 0.5944\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0434 - accuracy: 0.8981 - val_loss: 0.2742 - val_accuracy: 0.5975\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0403 - accuracy: 0.9052 - val_loss: 0.2793 - val_accuracy: 0.5991\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0389 - accuracy: 0.9095 - val_loss: 0.2897 - val_accuracy: 0.5903\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0407 - accuracy: 0.9041 - val_loss: 0.2883 - val_accuracy: 0.5923\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0436 - accuracy: 0.8986 - val_loss: 0.2917 - val_accuracy: 0.5859\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0450 - accuracy: 0.8947 - val_loss: 0.2886 - val_accuracy: 0.5813\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0429 - accuracy: 0.8991 - val_loss: 0.2929 - val_accuracy: 0.5828\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0391 - accuracy: 0.9086 - val_loss: 0.2931 - val_accuracy: 0.5834\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0435 - accuracy: 0.8984 - val_loss: 0.3001 - val_accuracy: 0.5741\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0383 - accuracy: 0.9106 - val_loss: 0.3272 - val_accuracy: 0.5506\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0511 - accuracy: 0.8830 - val_loss: 0.3146 - val_accuracy: 0.5700\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0388 - accuracy: 0.9102 - val_loss: 0.3095 - val_accuracy: 0.5655\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0356 - accuracy: 0.9179 - val_loss: 0.3131 - val_accuracy: 0.5691\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0337 - accuracy: 0.9226 - val_loss: 0.3174 - val_accuracy: 0.5702\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0333 - accuracy: 0.9227 - val_loss: 0.3187 - val_accuracy: 0.5720\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0304 - accuracy: 0.9284 - val_loss: 0.3229 - val_accuracy: 0.5733\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0307 - accuracy: 0.9296 - val_loss: 0.3308 - val_accuracy: 0.5672\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0307 - accuracy: 0.9291 - val_loss: 0.3386 - val_accuracy: 0.5733\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0351 - accuracy: 0.9209 - val_loss: 0.3323 - val_accuracy: 0.5616\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0354 - accuracy: 0.9188 - val_loss: 0.3427 - val_accuracy: 0.5544\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0370 - accuracy: 0.9157 - val_loss: 0.3302 - val_accuracy: 0.5633\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0326 - accuracy: 0.9255 - val_loss: 0.3394 - val_accuracy: 0.5622\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0311 - accuracy: 0.9281 - val_loss: 0.3475 - val_accuracy: 0.5562\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0315 - accuracy: 0.9279 - val_loss: 0.3476 - val_accuracy: 0.5569\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0290 - accuracy: 0.9328 - val_loss: 0.3631 - val_accuracy: 0.5542\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0273 - accuracy: 0.9363 - val_loss: 0.3607 - val_accuracy: 0.5580\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0257 - accuracy: 0.9410 - val_loss: 0.3643 - val_accuracy: 0.5494\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0265 - accuracy: 0.9393 - val_loss: 0.3680 - val_accuracy: 0.5573\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0298 - accuracy: 0.9334 - val_loss: 0.3868 - val_accuracy: 0.5495\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0397 - accuracy: 0.9121 - val_loss: 0.3754 - val_accuracy: 0.5395\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0412 - accuracy: 0.9072 - val_loss: 0.3754 - val_accuracy: 0.5412\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0353 - accuracy: 0.9207 - val_loss: 0.3737 - val_accuracy: 0.5439\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0312 - accuracy: 0.9299 - val_loss: 0.3782 - val_accuracy: 0.5412\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0336 - accuracy: 0.9251 - val_loss: 0.3839 - val_accuracy: 0.5298\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0374 - accuracy: 0.9154 - val_loss: 0.3780 - val_accuracy: 0.5345\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0293 - accuracy: 0.9342 - val_loss: 0.3805 - val_accuracy: 0.5372\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0259 - accuracy: 0.9416 - val_loss: 0.3843 - val_accuracy: 0.5384\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0245 - accuracy: 0.9440 - val_loss: 0.3903 - val_accuracy: 0.5427\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0230 - accuracy: 0.9480 - val_loss: 0.3981 - val_accuracy: 0.5408\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0224 - accuracy: 0.9496 - val_loss: 0.4030 - val_accuracy: 0.5397\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0227 - accuracy: 0.9495 - val_loss: 0.4061 - val_accuracy: 0.5330\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0227 - accuracy: 0.9498 - val_loss: 0.4052 - val_accuracy: 0.5370\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0210 - accuracy: 0.9523 - val_loss: 0.4066 - val_accuracy: 0.5372\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0206 - accuracy: 0.9536 - val_loss: 0.4183 - val_accuracy: 0.5384\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0213 - accuracy: 0.9522 - val_loss: 0.4195 - val_accuracy: 0.5342\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0354 - accuracy: 0.9222 - val_loss: 0.4040 - val_accuracy: 0.5295\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0414 - accuracy: 0.9097 - val_loss: 0.4000 - val_accuracy: 0.5200\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0375 - accuracy: 0.9173 - val_loss: 0.4266 - val_accuracy: 0.5213\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0321 - accuracy: 0.9289 - val_loss: 0.4135 - val_accuracy: 0.5269\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0257 - accuracy: 0.9436 - val_loss: 0.4140 - val_accuracy: 0.5245\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0291 - accuracy: 0.9355 - val_loss: 0.4236 - val_accuracy: 0.5233\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0260 - accuracy: 0.9427 - val_loss: 0.4316 - val_accuracy: 0.5250\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0218 - accuracy: 0.9518 - val_loss: 0.4379 - val_accuracy: 0.5261\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0209 - accuracy: 0.9530 - val_loss: 0.4443 - val_accuracy: 0.5242\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0190 - accuracy: 0.9577 - val_loss: 0.4429 - val_accuracy: 0.5253\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0184 - accuracy: 0.9585 - val_loss: 0.4514 - val_accuracy: 0.5227\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0201 - accuracy: 0.9561 - val_loss: 0.4543 - val_accuracy: 0.5228\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0206 - accuracy: 0.9541 - val_loss: 0.4614 - val_accuracy: 0.5186\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0275 - accuracy: 0.9408 - val_loss: 0.4517 - val_accuracy: 0.5125\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0362 - accuracy: 0.9234 - val_loss: 0.4441 - val_accuracy: 0.5092\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0390 - accuracy: 0.9169 - val_loss: 0.4509 - val_accuracy: 0.5042\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0288 - accuracy: 0.9366 - val_loss: 0.4451 - val_accuracy: 0.5161\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0230 - accuracy: 0.9494 - val_loss: 0.4562 - val_accuracy: 0.5195\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0192 - accuracy: 0.9579 - val_loss: 0.4640 - val_accuracy: 0.5195\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0180 - accuracy: 0.9604 - val_loss: 0.4686 - val_accuracy: 0.5169\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0170 - accuracy: 0.9632 - val_loss: 0.4771 - val_accuracy: 0.5127\n"
     ]
    }
   ],
   "source": [
    "# LSTM RNN\n",
    "model_bi_lstm = Sequential()\n",
    "model_bi_lstm.add(Embedding(num_vocab, 300, weights=[embedding_matrix], input_length=300, trainable=False))\n",
    "model_bi_lstm.add(Bidirectional(CuDNNLSTM(75)))\n",
    "model_bi_lstm.add(Dense(32, activation=\"relu\"))\n",
    "model_bi_lstm.add(Dense(13, activation=\"sigmoid\"))\n",
    "model_bi_lstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# Default padding is to the longest sequence\n",
    "for train_index, test_index in sss.split(sequences, target):\n",
    "    X_train, X_test = final_seqs[train_index], final_seqs[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "    hist = model_bi_lstm.fit(X_train, y_train, epochs=100, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
